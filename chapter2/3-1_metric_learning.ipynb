{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 距離学習のファインチューニング\n",
    "## ライブラリのインストール"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /home/ubuntu/finetuning_cookbook/.venv/lib/python3.10/site-packages (2.2.2)\n",
      "Requirement already satisfied: plotly in /home/ubuntu/finetuning_cookbook/.venv/lib/python3.10/site-packages (5.23.0)\n",
      "Requirement already satisfied: torch in /home/ubuntu/finetuning_cookbook/.venv/lib/python3.10/site-packages (2.4.0+cu118)\n",
      "Requirement already satisfied: torchvision in /home/ubuntu/finetuning_cookbook/.venv/lib/python3.10/site-packages (0.19.0+cu118)\n",
      "Requirement already satisfied: scikit-learn in /home/ubuntu/finetuning_cookbook/.venv/lib/python3.10/site-packages (1.5.1)\n",
      "Requirement already satisfied: tqdm in /home/ubuntu/finetuning_cookbook/.venv/lib/python3.10/site-packages (4.66.5)\n",
      "Requirement already satisfied: kaleido in /home/ubuntu/finetuning_cookbook/.venv/lib/python3.10/site-packages (0.2.1)\n",
      "Requirement already satisfied: nbformat in /home/ubuntu/finetuning_cookbook/.venv/lib/python3.10/site-packages (5.10.4)\n",
      "Requirement already satisfied: pytorch_metric_learning in /home/ubuntu/finetuning_cookbook/.venv/lib/python3.10/site-packages (2.6.0)\n",
      "Requirement already satisfied: numpy>=1.22.4 in /home/ubuntu/finetuning_cookbook/.venv/lib/python3.10/site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/ubuntu/finetuning_cookbook/.venv/lib/python3.10/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/ubuntu/finetuning_cookbook/.venv/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/ubuntu/finetuning_cookbook/.venv/lib/python3.10/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in /home/ubuntu/finetuning_cookbook/.venv/lib/python3.10/site-packages (from plotly) (9.0.0)\n",
      "Requirement already satisfied: packaging in /home/ubuntu/finetuning_cookbook/.venv/lib/python3.10/site-packages (from plotly) (24.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/ubuntu/finetuning_cookbook/.venv/lib/python3.10/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.3.0.86 in /home/ubuntu/finetuning_cookbook/.venv/lib/python3.10/site-packages (from torch) (10.3.0.86)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==9.1.0.70 in /home/ubuntu/finetuning_cookbook/.venv/lib/python3.10/site-packages (from torch) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.5.86 in /home/ubuntu/finetuning_cookbook/.venv/lib/python3.10/site-packages (from torch) (11.7.5.86)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.20.5 in /home/ubuntu/finetuning_cookbook/.venv/lib/python3.10/site-packages (from torch) (2.20.5)\n",
      "Requirement already satisfied: fsspec in /home/ubuntu/finetuning_cookbook/.venv/lib/python3.10/site-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.8.87 in /home/ubuntu/finetuning_cookbook/.venv/lib/python3.10/site-packages (from torch) (11.8.87)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.1.48 in /home/ubuntu/finetuning_cookbook/.venv/lib/python3.10/site-packages (from torch) (11.4.1.48)\n",
      "Requirement already satisfied: triton==3.0.0 in /home/ubuntu/finetuning_cookbook/.venv/lib/python3.10/site-packages (from torch) (3.0.0)\n",
      "Requirement already satisfied: networkx in /home/ubuntu/finetuning_cookbook/.venv/lib/python3.10/site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in /home/ubuntu/finetuning_cookbook/.venv/lib/python3.10/site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /home/ubuntu/finetuning_cookbook/.venv/lib/python3.10/site-packages (from torch) (10.9.0.58)\n",
      "Requirement already satisfied: sympy in /home/ubuntu/finetuning_cookbook/.venv/lib/python3.10/site-packages (from torch) (1.13.2)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.8.89 in /home/ubuntu/finetuning_cookbook/.venv/lib/python3.10/site-packages (from torch) (11.8.89)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.11.3.6 in /home/ubuntu/finetuning_cookbook/.venv/lib/python3.10/site-packages (from torch) (11.11.3.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.8.89 in /home/ubuntu/finetuning_cookbook/.venv/lib/python3.10/site-packages (from torch) (11.8.89)\n",
      "Requirement already satisfied: filelock in /home/ubuntu/finetuning_cookbook/.venv/lib/python3.10/site-packages (from torch) (3.15.4)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.8.86 in /home/ubuntu/finetuning_cookbook/.venv/lib/python3.10/site-packages (from torch) (11.8.86)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/ubuntu/finetuning_cookbook/.venv/lib/python3.10/site-packages (from torchvision) (10.4.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/ubuntu/finetuning_cookbook/.venv/lib/python3.10/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/ubuntu/finetuning_cookbook/.venv/lib/python3.10/site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /home/ubuntu/finetuning_cookbook/.venv/lib/python3.10/site-packages (from scikit-learn) (1.14.1)\n",
      "Requirement already satisfied: jsonschema>=2.6 in /home/ubuntu/finetuning_cookbook/.venv/lib/python3.10/site-packages (from nbformat) (4.23.0)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /home/ubuntu/finetuning_cookbook/.venv/lib/python3.10/site-packages (from nbformat) (5.7.2)\n",
      "Requirement already satisfied: traitlets>=5.1 in /home/ubuntu/finetuning_cookbook/.venv/lib/python3.10/site-packages (from nbformat) (5.14.3)\n",
      "Requirement already satisfied: fastjsonschema>=2.15 in /home/ubuntu/finetuning_cookbook/.venv/lib/python3.10/site-packages (from nbformat) (2.20.0)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /home/ubuntu/finetuning_cookbook/.venv/lib/python3.10/site-packages (from jsonschema>=2.6->nbformat) (24.2.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /home/ubuntu/finetuning_cookbook/.venv/lib/python3.10/site-packages (from jsonschema>=2.6->nbformat) (2023.12.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /home/ubuntu/finetuning_cookbook/.venv/lib/python3.10/site-packages (from jsonschema>=2.6->nbformat) (0.35.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /home/ubuntu/finetuning_cookbook/.venv/lib/python3.10/site-packages (from jsonschema>=2.6->nbformat) (0.20.0)\n",
      "Requirement already satisfied: platformdirs>=2.5 in /home/ubuntu/finetuning_cookbook/.venv/lib/python3.10/site-packages (from jupyter-core!=5.0.*,>=4.12->nbformat) (4.2.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/ubuntu/finetuning_cookbook/.venv/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/ubuntu/finetuning_cookbook/.venv/lib/python3.10/site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/ubuntu/finetuning_cookbook/.venv/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pandas plotly torch torchvision scikit-learn plotly tqdm kaleido nbformat pytorch_metric_learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.models as models\n",
    "from pytorch_metric_learning import distances, losses, regularizers\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader, SubsetRandomSampler\n",
    "from torchvision import datasets, transforms\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習コードの作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_sampler(dataset, subset_size=1000, random_seed=42):\n",
    "    \"\"\"データセットからランダムにデータを取得するためのSubsetRandomSamplerを作成する\n",
    "\n",
    "    Args:\n",
    "        dataset (_type_): 対象データセット\n",
    "        subset_size (int, optional): ランダムに抽出するデータ数. Defaults to 1000.\n",
    "        random_seed (int, optional): seed値. Defaults to 42.\n",
    "\n",
    "    Returns:\n",
    "        _type_: _description_\n",
    "    \"\"\"\n",
    "    # データセットのインデックス配列を作成する\n",
    "    indices = list(range(len(dataset)))\n",
    "    # インデックスをシャッフルする\n",
    "    np.random.seed(random_seed)\n",
    "    np.random.shuffle(indices)\n",
    "    # シャッフルしたインデックスからsubset_size分だけ取得する\n",
    "    subset_indices = indices[:subset_size]\n",
    "    # SubsetRandomSamplerにインデックスを渡すことで、そのインデックスのデータをサンプリングする\n",
    "    return SubsetRandomSampler(subset_indices)\n",
    "\n",
    "\n",
    "def train_epoch(model, train_loader, criterion, optimizer, device):\n",
    "    \"\"\"1エポック分の学習を行う\n",
    "\n",
    "    Args:\n",
    "        model (_type_):\n",
    "        train_loader (_type_):\n",
    "        criterion (_type_):\n",
    "        optimizer (_type_):\n",
    "        device (_type_):\n",
    "\n",
    "    Returns:\n",
    "        _type_: _description_\n",
    "    \"\"\"\n",
    "    # モデルをtrainモードにする\n",
    "    model.train()\n",
    "    # 損失を記録する変数を定義\n",
    "    running_loss = 0.0\n",
    "\n",
    "    # ミニバッチごとにループを回す\n",
    "    for images, labels in tqdm(train_loader, total=len(train_loader)):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        # 勾配を初期化する\n",
    "        optimizer.zero_grad()\n",
    "        # 準伝搬\n",
    "        outputs = model(images)\n",
    "        # 損失関数を計算\n",
    "        loss = criterion(outputs, labels)\n",
    "        # 逆伝搬\n",
    "        loss.backward()\n",
    "        # パラメータ更新\n",
    "        optimizer.step()\n",
    "\n",
    "        # ミニバッチの損失を計算し記録する\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    # 1エポックあたりの平均損失を計算する\n",
    "    avg_loss = running_loss / len(train_loader)\n",
    "    return avg_loss\n",
    "\n",
    "\n",
    "def validate_epoch(model, val_loader, criterion, device):\n",
    "    \"\"\"1エポック分の検証を行う\n",
    "\n",
    "    Args:\n",
    "        model (_type_): _description_\n",
    "        val_loader (_type_): _description_\n",
    "        criterion (_type_): _description_\n",
    "        device (_type_): _description_\n",
    "\n",
    "    Returns:\n",
    "        _type_: _description_\n",
    "    \"\"\"\n",
    "    # モデルをevalモードにする\n",
    "    model.eval()\n",
    "    # 損失を記録する変数を定義\n",
    "    running_loss = 0.0\n",
    "\n",
    "    all_output = []\n",
    "    all_labels = []\n",
    "    # 勾配計算をしないようにする(推論なので)\n",
    "    with torch.no_grad():\n",
    "        # ミニバッチごとにループを回す\n",
    "        for images, labels in tqdm(val_loader, total=len(val_loader)):\n",
    "            # デバイスの指定\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            # 準伝搬\n",
    "            outputs = model(images)\n",
    "            all_output.append(outputs)\n",
    "            all_labels.append(labels)\n",
    "            # 損失計算\n",
    "            loss = criterion(outputs, labels)\n",
    "            # 損失を記録する\n",
    "            running_loss += loss.item()\n",
    "\n",
    "    # 1エポックあたりの平均損失を計算する\n",
    "    avg_loss = running_loss / len(val_loader)\n",
    "    # テストデータの予測結果を取得する\n",
    "    all_output = torch.cat(all_output, dim=0).cpu()\n",
    "    all_labels = torch.cat(all_labels, dim=0).cpu()\n",
    "    return avg_loss, all_output, all_labels\n",
    "\n",
    "\n",
    "def get_cifar10_train_test_loader(\n",
    "    train_samples: int = 1000,\n",
    "    test_samples: int = 1000,\n",
    "    resize: tuple[int, int] = (256, 256),\n",
    "    batch_size: int = 32,\n",
    "):\n",
    "    \"\"\"CIFAR-10データセットの学習データと検証データのDataLoaderを作成する\n",
    "\n",
    "    Args:\n",
    "        train_samples (int, optional): _description_. Defaults to 1000.\n",
    "        test_samples (int, optional): _description_. Defaults to 1000.\n",
    "        resize (tuple[int, int], optional): _description_. Defaults to (256, 256).\n",
    "        batch_size (int, optional): _description_. Defaults to 32.\n",
    "\n",
    "    Returns:\n",
    "        _type_: _description_\n",
    "    \"\"\"\n",
    "    # 画像を256x156にリサイズして、テンソルに変換する\n",
    "    transform = transforms.Compose([transforms.Resize(resize), transforms.ToTensor()])\n",
    "\n",
    "    # 学習データセットの作成\n",
    "    train_dataset = datasets.CIFAR10(\n",
    "        root=\"./data\", train=True, download=True, transform=transform\n",
    "    )\n",
    "    # データセットからランダムにデータを取得する\n",
    "    train_sampler = get_random_sampler(train_dataset, train_samples)\n",
    "    # 学習DataLoaderの作成\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset, batch_size=batch_size, sampler=train_sampler\n",
    "    )\n",
    "\n",
    "    # 検証データセットの作成\n",
    "    test_dataset = datasets.CIFAR10(\n",
    "        root=\"./data\", train=False, download=True, transform=transform\n",
    "    )\n",
    "    # データセットからランダムにデータを取得する\n",
    "    test_sampler = get_random_sampler(test_dataset, test_samples)\n",
    "    # 検証DataLoaderの作成\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, sampler=test_sampler)\n",
    "    return train_loader, test_loader\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データのダウンロード\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# データをロードする\n",
    "train_loader, test_loader = get_cifar10_train_test_loader(\n",
    "    train_samples=5000, test_samples=1000\n",
    ")\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## モデルの作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(pretrained: bool = True, state_dict: dict | None = None):\n",
    "    # 距離学習\n",
    "    # 事前学習済みのResNetモデルをロード\n",
    "    model = models.resnet50(pretrained=pretrained)\n",
    "    # ResNetの最後の全結合層をembedding数に置き換え\n",
    "    model.fc = nn.Linear(model.fc.in_features, 128)\n",
    "    if state_dict is not None:\n",
    "        model.load_state_dict(state_dict)\n",
    "    # デバイスの設定\n",
    "    model.to(device)\n",
    "    # ArcFace lossの設定\n",
    "    # コサイン類似度を使う\n",
    "    distance = distances.CosineSimilarity()\n",
    "    regularizer = regularizers.RegularFaceRegularizer()\n",
    "    criterion = losses.ArcFaceLoss(\n",
    "        num_classes=10,\n",
    "        embedding_size=128,\n",
    "        margin=28.6,\n",
    "        scale=64,\n",
    "        weight_regularizer=regularizer,\n",
    "        distance=distance,\n",
    "    )\n",
    "    # GPUが使えるなら使う\n",
    "    if device != \"cpu\":\n",
    "        criterion = criterion.cuda()\n",
    "\n",
    "    # オプティマイザの設定\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    return model, criterion, optimizer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## モデルの学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルの出力をKNNでラベルに変換する\n",
    "def eval(model, train_loader, test_loader):\n",
    "    # モデルをevalモードにする\n",
    "    model.eval()\n",
    "\n",
    "    x_train = []\n",
    "    x_test = []\n",
    "    y_train = []\n",
    "    y_test = []\n",
    "    with torch.no_grad():\n",
    "        # 学習データの推論結果を得る\n",
    "        for x_org, y in tqdm(train_loader, total=len(train_loader)):\n",
    "            # デバイスの指定\n",
    "            x_org, y = x_org.to(device), y.to(device)\n",
    "            # モデルでx_orgを新しい空間に写像\n",
    "            x = model(x_org)\n",
    "            x_train.append(x)\n",
    "            y_train.append(y)\n",
    "        # テストデータの推論結果を得る\n",
    "        for x_org, y in tqdm(test_loader, total=len(test_loader)):\n",
    "            # デバイスの指定\n",
    "            x_org, y = x_org.to(device), y.to(device)\n",
    "            x = model(x_org)\n",
    "            x_test.append(x)\n",
    "            y_test.append(y)\n",
    "    # データを変換する\n",
    "    x_train = torch.cat(x_train).cpu().numpy()\n",
    "    x_test = torch.cat(x_test).cpu().numpy()\n",
    "    y_train = torch.cat(y_train).cpu().numpy()\n",
    "    y_test = torch.cat(y_test).cpu().numpy()\n",
    "\n",
    "    # KNNモデルを作成\n",
    "    knn = KNeighborsClassifier(n_neighbors=5, metric=\"cosine\")\n",
    "    # KNNモデルを学習データの結果で学習する\n",
    "    knn.fit(x_train, y_train)\n",
    "\n",
    "    # テストデータの推定ラベルをKNNモデルで推論\n",
    "    y_pred = knn.predict(x_test)\n",
    "\n",
    "    return {\n",
    "        \"x_train\": x_train,\n",
    "        \"x_test\": x_test,\n",
    "        \"y_train\": y_train,\n",
    "        \"y_test\": y_test,\n",
    "        \"y_pred\": y_pred,\n",
    "    }\n",
    "\n",
    "\n",
    "def run(\n",
    "    pretrained: bool = True,\n",
    "    num_epochs: int = 100,\n",
    "):\n",
    "    # 距離学習\n",
    "    # 事前学習済みのResNetモデルをロード\n",
    "    model, criterion, optimizer = get_model(pretrained=pretrained)\n",
    "\n",
    "    result = []\n",
    "    # 出力先のディレクトリを作成\n",
    "    output_dir = Path(\n",
    "        \"output\", \"metric_learning\", \"pretrained\" if pretrained else \"un_pretrained\"\n",
    "    )\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    # 学習\n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss = train_epoch(model, train_loader, criterion, optimizer, device)\n",
    "        val_loss, output, labels = validate_epoch(model, test_loader, criterion, device)\n",
    "\n",
    "        print(\n",
    "            f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.4f}, Validation Loss: {val_loss:.4f}\"\n",
    "        )\n",
    "        # KNNで評価する\n",
    "        knn_result = eval(model, train_loader, test_loader)\n",
    "        # ラベルの正解率\n",
    "        label_acc = (knn_result[\"y_pred\"] == knn_result[\"y_test\"]).sum() / len(\n",
    "            knn_result[\"y_test\"]\n",
    "        )\n",
    "        result.append(\n",
    "            {\"train_loss\": train_loss, \"val_loss\": val_loss, \"val_acc\": label_acc}\n",
    "        )\n",
    "        # 結果を保存する\n",
    "        torch.save(\n",
    "            {\"output\": output, \"label\": labels, \"pred_labels\": knn_result[\"y_pred\"]},\n",
    "            output_dir / f\"epoch_{epoch}_output.pt\",\n",
    "        )\n",
    "\n",
    "    df_result = pd.DataFrame(result)\n",
    "    df_result.to_csv(output_dir / \"training_curve.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/finetuning_cookbook/.venv/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/finetuning_cookbook/.venv/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "100%|██████████| 157/157 [00:31<00:00,  4.99it/s]\n",
      "100%|██████████| 32/32 [00:02<00:00, 12.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Train Loss: 30.3586, Validation Loss: 29.0352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:07<00:00, 20.92it/s]\n",
      "100%|██████████| 32/32 [00:01<00:00, 21.34it/s]\n",
      "100%|██████████| 157/157 [00:30<00:00,  5.14it/s]\n",
      "100%|██████████| 32/32 [00:03<00:00, 10.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10, Train Loss: 28.9210, Validation Loss: 28.3505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:09<00:00, 17.23it/s]\n",
      "100%|██████████| 32/32 [00:01<00:00, 16.56it/s]\n",
      "100%|██████████| 157/157 [00:30<00:00,  5.17it/s]\n",
      "100%|██████████| 32/32 [00:02<00:00, 11.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10, Train Loss: 28.5274, Validation Loss: 28.5285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:07<00:00, 20.15it/s]\n",
      "100%|██████████| 32/32 [00:01<00:00, 21.54it/s]\n",
      "100%|██████████| 157/157 [00:31<00:00,  4.96it/s]\n",
      "100%|██████████| 32/32 [00:02<00:00, 11.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10, Train Loss: 28.1409, Validation Loss: 28.5218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:08<00:00, 19.54it/s]\n",
      "100%|██████████| 32/32 [00:01<00:00, 21.44it/s]\n",
      "100%|██████████| 157/157 [00:30<00:00,  5.12it/s]\n",
      "100%|██████████| 32/32 [00:02<00:00, 12.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10, Train Loss: 27.6627, Validation Loss: 28.1564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|████▉     | 78/157 [00:04<00:05, 13.62it/s]"
     ]
    }
   ],
   "source": [
    "run(pretrained=True, num_epochs=10)\n",
    "# run(train_samples=5000, test_samples=1000, pretrained=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## モデルの評価\n",
    "学習済みモデルをロードし、テストデータで評価する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_loader_to_array(data_loader):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for image, label in data_loader:\n",
    "        images.append(image)\n",
    "        labels.append(label)\n",
    "\n",
    "    data = torch.cat(images)\n",
    "    label = torch.cat(labels)\n",
    "\n",
    "    data_reshaped = data.view(data.shape[0], -1).numpy()\n",
    "    return data_reshaped, label\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### t-SNEによる可視化\n",
    "モデルの出力をt-SNEで次元圧縮し、可視化する\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## t-SNEによる次元圧縮\n",
    "data_reshaped, label = data_loader_to_array(test_loader)\n",
    "\n",
    "\n",
    "def plot_tsne(data, label):\n",
    "    tsne = TSNE(n_components=2, random_state=0)\n",
    "    data_tsne = tsne.fit_transform(data)\n",
    "    df = pd.DataFrame(data_tsne, columns=[\"x\", \"y\"])\n",
    "    df[\"label\"] = label.numpy().astype(str)\n",
    "    df = df.sort_values(\"label\")\n",
    "\n",
    "    fig = px.scatter(\n",
    "        df,\n",
    "        x=\"x\",\n",
    "        y=\"y\",\n",
    "        title=\"t-SNE Visualization of Image Data\",\n",
    "        color=\"label\",\n",
    "    )\n",
    "    fig.update_layout(legend_title=\"label\")\n",
    "    return fig\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 学習前のデータをt-SNEで可視化\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_tsne(data_reshaped, label)\n",
    "fig.write_image(\"output/metric_learning/tsne_org.png\")\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 学習後のデータをt-SNEで可視化\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "outputs = sorted(list(Path(\"output/metric_learning/pretrained\").glob(\"**/epoch_*\")))\n",
    "print(outputs)\n",
    "\n",
    "for i, output in tqdm(enumerate(outputs)):\n",
    "    if i % 10 != 0:\n",
    "        continue\n",
    "    loaded_data = torch.load(output)\n",
    "    output_data = loaded_data[\"output\"]\n",
    "    true_label = loaded_data[\"label\"]\n",
    "\n",
    "    fig = plot_tsne(output_data, true_label)\n",
    "    fig.write_image(f\"output/metric_learning/tsne_epoch_{i}.png\")\n",
    "fig\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 学習曲線を可視化\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.line(\n",
    "    pd.read_csv(\"output/metric_learning/pretrained/training_curve.csv\"),\n",
    "    y=[\"train_loss\", \"val_loss\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.line(\n",
    "    pd.read_csv(\"output/metric_learning/pretrained/training_curve.csv\"),\n",
    "    y=[\"val_acc\"],\n",
    ")\n",
    "fig.update_layout(title=\"KNNによるAccuracy\")\n",
    "fig.update_yaxes(title=\"validation Accuracy\")\n",
    "fig.update_xaxes(title=\"epoch\")\n",
    "fig.write_image(\"output/metric_learning/pretrained/accuracy.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
