{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 距離学習のファインチューニング\n",
    "## ライブラリのインストール"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pandas plotly torch torchvision scikit-learn plotly tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.models as models\n",
    "from pytorch_metric_learning import distances, losses, regularizers\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader, SubsetRandomSampler\n",
    "from torchvision import datasets, transforms\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習コードの作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_random_sampler(dataset, subset_size=1000, random_seed=42):\n",
    "    \"\"\"データセットからランダムにデータを取得するためのSubsetRandomSamplerを作成する\n",
    "\n",
    "    Args:\n",
    "        dataset (_type_): 対象データセット\n",
    "        subset_size (int, optional): ランダムに抽出するデータ数. Defaults to 1000.\n",
    "        random_seed (int, optional): seed値. Defaults to 42.\n",
    "\n",
    "    Returns:\n",
    "        _type_: _description_\n",
    "    \"\"\"\n",
    "    # データセットのインデックス配列を作成する\n",
    "    indices = list(range(len(dataset)))\n",
    "    # インデックスをシャッフルする\n",
    "    np.random.seed(random_seed)\n",
    "    np.random.shuffle(indices)\n",
    "    # シャッフルしたインデックスからsubset_size分だけ取得する\n",
    "    subset_indices = indices[:subset_size]\n",
    "    # SubsetRandomSamplerにインデックスを渡すことで、そのインデックスのデータをサンプリングする\n",
    "    return SubsetRandomSampler(subset_indices)\n",
    "\n",
    "\n",
    "def train_epoch(model, train_loader, criterion, optimizer, device):\n",
    "    \"\"\"1エポック分の学習を行う\n",
    "\n",
    "    Args:\n",
    "        model (_type_):\n",
    "        train_loader (_type_):\n",
    "        criterion (_type_):\n",
    "        optimizer (_type_):\n",
    "        device (_type_):\n",
    "\n",
    "    Returns:\n",
    "        _type_: _description_\n",
    "    \"\"\"\n",
    "    # モデルをtrainモードにする\n",
    "    model.train()\n",
    "    # 損失を記録する変数を定義\n",
    "    running_loss = 0.0\n",
    "\n",
    "    # ミニバッチごとにループを回す\n",
    "    for images, labels in tqdm(train_loader, total=len(train_loader)):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        # 勾配を初期化する\n",
    "        optimizer.zero_grad()\n",
    "        # 準伝搬\n",
    "        outputs = model(images)\n",
    "        # 損失関数を計算\n",
    "        loss = criterion(outputs, labels)\n",
    "        # 逆伝搬\n",
    "        loss.backward()\n",
    "        # パラメータ更新\n",
    "        optimizer.step()\n",
    "\n",
    "        # ミニバッチの損失を計算し記録する\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    # 1エポックあたりの平均損失を計算する\n",
    "    avg_loss = running_loss / len(train_loader)\n",
    "    return avg_loss\n",
    "\n",
    "\n",
    "def validate_epoch(model, val_loader, criterion, device):\n",
    "    \"\"\"1エポック分の検証を行う\n",
    "\n",
    "    Args:\n",
    "        model (_type_): _description_\n",
    "        val_loader (_type_): _description_\n",
    "        criterion (_type_): _description_\n",
    "        device (_type_): _description_\n",
    "\n",
    "    Returns:\n",
    "        _type_: _description_\n",
    "    \"\"\"\n",
    "    # モデルをevalモードにする\n",
    "    model.eval()\n",
    "    # 損失を記録する変数を定義\n",
    "    running_loss = 0.0\n",
    "\n",
    "    all_output = []\n",
    "    all_labels = []\n",
    "    # 勾配計算をしないようにする(推論なので)\n",
    "    with torch.no_grad():\n",
    "        # ミニバッチごとにループを回す\n",
    "        for images, labels in tqdm(val_loader, total=len(val_loader)):\n",
    "            # デバイスの指定\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            # 準伝搬\n",
    "            outputs = model(images)\n",
    "            all_output.append(outputs)\n",
    "            all_labels.append(labels)\n",
    "            # 損失計算\n",
    "            loss = criterion(outputs, labels)\n",
    "            # 損失を記録する\n",
    "            running_loss += loss.item()\n",
    "\n",
    "    # 1エポックあたりの平均損失を計算する\n",
    "    avg_loss = running_loss / len(val_loader)\n",
    "    # テストデータの予測結果を取得する\n",
    "    all_output = torch.cat(all_output, dim=0).cpu()\n",
    "    all_labels = torch.cat(all_labels, dim=0).cpu()\n",
    "    return avg_loss, all_output, all_labels\n",
    "\n",
    "\n",
    "def get_cifar10_train_test_loader(\n",
    "    train_samples: int = 1000,\n",
    "    test_samples: int = 1000,\n",
    "    resize: tuple[int, int] = (256, 256),\n",
    "    batch_size: int = 32,\n",
    "):\n",
    "    \"\"\"CIFAR-10データセットの学習データと検証データのDataLoaderを作成する\n",
    "\n",
    "    Args:\n",
    "        train_samples (int, optional): _description_. Defaults to 1000.\n",
    "        test_samples (int, optional): _description_. Defaults to 1000.\n",
    "        resize (tuple[int, int], optional): _description_. Defaults to (256, 256).\n",
    "        batch_size (int, optional): _description_. Defaults to 32.\n",
    "\n",
    "    Returns:\n",
    "        _type_: _description_\n",
    "    \"\"\"\n",
    "    # 画像を256x156にリサイズして、テンソルに変換する\n",
    "    transform = transforms.Compose([transforms.Resize(resize), transforms.ToTensor()])\n",
    "\n",
    "    # 学習データセットの作成\n",
    "    train_dataset = datasets.CIFAR10(\n",
    "        root=\"./data\", train=True, download=True, transform=transform\n",
    "    )\n",
    "    # データセットからランダムにデータを取得する\n",
    "    train_sampler = get_random_sampler(train_dataset, train_samples)\n",
    "    # 学習DataLoaderの作成\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset, batch_size=batch_size, sampler=train_sampler\n",
    "    )\n",
    "\n",
    "    # 検証データセットの作成\n",
    "    test_dataset = datasets.CIFAR10(\n",
    "        root=\"./data\", train=False, download=True, transform=transform\n",
    "    )\n",
    "    # データセットからランダムにデータを取得する\n",
    "    test_sampler = get_random_sampler(test_dataset, test_samples)\n",
    "    # 検証DataLoaderの作成\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, sampler=test_sampler)\n",
    "    return train_loader, test_loader\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データのダウンロード\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データをロードする\n",
    "train_loader, test_loader = get_cifar10_train_test_loader(\n",
    "    train_samples=5000, test_samples=1000\n",
    ")\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## モデルの作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(pretrained: bool = True, state_dict: dict | None = None):\n",
    "    # 距離学習\n",
    "    # 事前学習済みのResNetモデルをロード\n",
    "    model = models.resnet50(pretrained=pretrained)\n",
    "    # ResNetの最後の全結合層をembedding数に置き換え\n",
    "    model.fc = nn.Linear(model.fc.in_features, 128)\n",
    "    if state_dict is not None:\n",
    "        model.load_state_dict(state_dict)\n",
    "    # デバイスの設定\n",
    "    model.to(device)\n",
    "    # ArcFace lossの設定\n",
    "    # コサイン類似度を使う\n",
    "    distance = distances.CosineSimilarity()\n",
    "    regularizer = regularizers.RegularFaceRegularizer()\n",
    "    criterion = losses.ArcFaceLoss(\n",
    "        num_classes=10,\n",
    "        embedding_size=128,\n",
    "        margin=28.6,\n",
    "        scale=64,\n",
    "        weight_regularizer=regularizer,\n",
    "        distance=distance,\n",
    "    )\n",
    "    # GPUが使えるなら使う\n",
    "    if device != \"cpu\":\n",
    "        criterion = criterion.cuda()\n",
    "\n",
    "    # オプティマイザの設定\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    return model, criterion, optimizer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## モデルの学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルの出力をKNNでラベルに変換する\n",
    "def eval(model, train_loader, test_loader):\n",
    "    # モデルをevalモードにする\n",
    "    model.eval()\n",
    "\n",
    "    x_train = []\n",
    "    x_test = []\n",
    "    y_train = []\n",
    "    y_test = []\n",
    "    with torch.no_grad():\n",
    "        # 学習データの推論結果を得る\n",
    "        for x_org, y in tqdm(train_loader, total=len(train_loader)):\n",
    "            # デバイスの指定\n",
    "            x_org, y = x_org.to(device), y.to(device)\n",
    "            # モデルでx_orgを新しい空間に写像\n",
    "            x = model(x_org)\n",
    "            x_train.append(x)\n",
    "            y_train.append(y)\n",
    "        # テストデータの推論結果を得る\n",
    "        for x_org, y in tqdm(test_loader, total=len(test_loader)):\n",
    "            # デバイスの指定\n",
    "            x_org, y = x_org.to(device), y.to(device)\n",
    "            x = model(x_org)\n",
    "            x_test.append(x)\n",
    "            y_test.append(y)\n",
    "    # データを変換する\n",
    "    x_train = torch.cat(x_train).cpu().numpy()\n",
    "    x_test = torch.cat(x_test).cpu().numpy()\n",
    "    y_train = torch.cat(y_train).cpu().numpy()\n",
    "    y_test = torch.cat(y_test).cpu().numpy()\n",
    "\n",
    "    # KNNモデルを作成\n",
    "    knn = KNeighborsClassifier(n_neighbors=5, metric=\"cosine\")\n",
    "    # KNNモデルを学習データの結果で学習する\n",
    "    knn.fit(x_train, y_train)\n",
    "\n",
    "    # テストデータの推定ラベルをKNNモデルで推論\n",
    "    y_pred = knn.predict(x_test)\n",
    "\n",
    "    return {\n",
    "        \"x_train\": x_train,\n",
    "        \"x_test\": x_test,\n",
    "        \"y_train\": y_train,\n",
    "        \"y_test\": y_test,\n",
    "        \"y_pred\": y_pred,\n",
    "    }\n",
    "\n",
    "\n",
    "def run(\n",
    "    pretrained: bool = True,\n",
    "    num_epochs: int = 100,\n",
    "):\n",
    "    # 距離学習\n",
    "    # 事前学習済みのResNetモデルをロード\n",
    "    model, criterion, optimizer = get_model(pretrained=pretrained)\n",
    "\n",
    "    result = []\n",
    "    output_dir = Path(\n",
    "        \"output\", \"metric_learning\", \"pretrained\" if pretrained else \"un_pretrained\"\n",
    "    )\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss = train_epoch(model, train_loader, criterion, optimizer, device)\n",
    "        val_loss, output, labels = validate_epoch(model, test_loader, criterion, device)\n",
    "\n",
    "        print(\n",
    "            f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.4f}, Validation Loss: {val_loss:.4f}\"\n",
    "        )\n",
    "        # KNNで評価する\n",
    "        knn_result = eval(model, train_loader, test_loader)\n",
    "        # ラベルの正解率\n",
    "        label_acc = (knn_result[\"y_pred\"] == knn_result[\"y_test\"]).sum() / len(\n",
    "            knn_result[\"y_test\"]\n",
    "        )\n",
    "        result.append(\n",
    "            {\"train_loss\": train_loss, \"val_loss\": val_loss, \"val_acc\": label_acc}\n",
    "        )\n",
    "        torch.save(\n",
    "            {\"output\": output, \"label\": labels, \"pred_labels\": knn_result[\"y_pred\"]},\n",
    "            output_dir / f\"epoch_{epoch}_output.pt\",\n",
    "        )\n",
    "\n",
    "    df_result = pd.DataFrame(result)\n",
    "    df_result.to_csv(output_dir / \"training_curve.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/finetuning_cookbook_staging/.venv/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/finetuning_cookbook_staging/.venv/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The NVIDIA driver on your system is too old (found version 11020). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpretrained\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# run(train_samples=5000, test_samples=1000, pretrained=False)\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[6], line 55\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(pretrained, num_epochs)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun\u001b[39m(\n\u001b[1;32m     50\u001b[0m     pretrained: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     51\u001b[0m     num_epochs: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m100\u001b[39m,\n\u001b[1;32m     52\u001b[0m ):\n\u001b[1;32m     53\u001b[0m     \u001b[38;5;66;03m# 距離学習\u001b[39;00m\n\u001b[1;32m     54\u001b[0m     \u001b[38;5;66;03m# 事前学習済みのResNetモデルをロード\u001b[39;00m\n\u001b[0;32m---> 55\u001b[0m     model, criterion, optimizer \u001b[38;5;241m=\u001b[39m \u001b[43mget_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpretrained\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpretrained\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     57\u001b[0m     result \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     58\u001b[0m     output_dir \u001b[38;5;241m=\u001b[39m Path(\n\u001b[1;32m     59\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetric_learning\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpretrained\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m pretrained \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mun_pretrained\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     60\u001b[0m     )\n",
      "Cell \u001b[0;32mIn[5], line 25\u001b[0m, in \u001b[0;36mget_model\u001b[0;34m(pretrained, state_dict)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# GPUが使えるなら使う\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m device \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 25\u001b[0m     criterion \u001b[38;5;241m=\u001b[39m \u001b[43mcriterion\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# オプティマイザの設定\u001b[39;00m\n\u001b[1;32m     28\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mAdam(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m)\n",
      "File \u001b[0;32m~/finetuning_cookbook_staging/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:916\u001b[0m, in \u001b[0;36mModule.cuda\u001b[0;34m(self, device)\u001b[0m\n\u001b[1;32m    899\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcuda\u001b[39m(\u001b[38;5;28mself\u001b[39m: T, device: Optional[Union[\u001b[38;5;28mint\u001b[39m, device]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m T:\n\u001b[1;32m    900\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Move all model parameters and buffers to the GPU.\u001b[39;00m\n\u001b[1;32m    901\u001b[0m \n\u001b[1;32m    902\u001b[0m \u001b[38;5;124;03m    This also makes associated parameters and buffers different objects. So\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    914\u001b[0m \u001b[38;5;124;03m        Module: self\u001b[39;00m\n\u001b[1;32m    915\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 916\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/finetuning_cookbook_staging/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:805\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    801\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    802\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    803\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    804\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 805\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    806\u001b[0m p_should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    808\u001b[0m \u001b[38;5;66;03m# subclasses may have multiple child tensors so we need to use swap_tensors\u001b[39;00m\n",
      "File \u001b[0;32m~/finetuning_cookbook_staging/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:916\u001b[0m, in \u001b[0;36mModule.cuda.<locals>.<lambda>\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    899\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcuda\u001b[39m(\u001b[38;5;28mself\u001b[39m: T, device: Optional[Union[\u001b[38;5;28mint\u001b[39m, device]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m T:\n\u001b[1;32m    900\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Move all model parameters and buffers to the GPU.\u001b[39;00m\n\u001b[1;32m    901\u001b[0m \n\u001b[1;32m    902\u001b[0m \u001b[38;5;124;03m    This also makes associated parameters and buffers different objects. So\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    914\u001b[0m \u001b[38;5;124;03m        Module: self\u001b[39;00m\n\u001b[1;32m    915\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 916\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_apply(\u001b[38;5;28;01mlambda\u001b[39;00m t: \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/finetuning_cookbook_staging/.venv/lib/python3.10/site-packages/torch/cuda/__init__.py:314\u001b[0m, in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    312\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCUDA_MODULE_LOADING\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39menviron:\n\u001b[1;32m    313\u001b[0m     os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCUDA_MODULE_LOADING\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLAZY\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 314\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cuda_init\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    315\u001b[0m \u001b[38;5;66;03m# Some of the queued calls may reentrantly call _lazy_init();\u001b[39;00m\n\u001b[1;32m    316\u001b[0m \u001b[38;5;66;03m# we need to just return without initializing in that case.\u001b[39;00m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;66;03m# However, we must not let any *other* threads in!\u001b[39;00m\n\u001b[1;32m    318\u001b[0m _tls\u001b[38;5;241m.\u001b[39mis_initializing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The NVIDIA driver on your system is too old (found version 11020). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver."
     ]
    }
   ],
   "source": [
    "run(pretrained=True)\n",
    "# run(train_samples=5000, test_samples=1000, pretrained=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルの出力を確認\n",
    "torch.load(\"output/metric_learning/pretrained/epoch_25_output.pt\")[\"pred_labels\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## モデルの評価\n",
    "学習済みモデルをロードし、テストデータで評価する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_model, _, _ = get_model(\n",
    "    state_dict=torch.load(\"output/metric_learning/pretrained/epoch_50/check_point.pt\"),\n",
    ")\n",
    "eval_result = eval(\n",
    "    eval_model,\n",
    "    train_loader=train_loader,\n",
    "    test_loader=test_loader,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(\n",
    "    classification_report(\n",
    "        eval_result[\"y_test\"], eval_result[\"y_pred\"], output_dict=True\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(eval_result[\"y_pred\"] == eval_result[\"y_test\"]).sum() / len(eval_result[\"y_test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_loader_to_array(data_loader):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for image, label in data_loader:\n",
    "        images.append(image)\n",
    "        labels.append(label)\n",
    "\n",
    "    data = torch.cat(images)\n",
    "    label = torch.cat(labels)\n",
    "\n",
    "    data_reshaped = data.view(data.shape[0], -1).numpy()\n",
    "    return data_reshaped, label\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## t-SNEによる次元圧縮\n",
    "data_reshaped, label = data_loader_to_array(test_loader)\n",
    "\n",
    "\n",
    "def plot_tsne(data, label):\n",
    "    tsne = TSNE(n_components=2, random_state=0)\n",
    "    data_tsne = tsne.fit_transform(data)\n",
    "    df = pd.DataFrame(data_tsne, columns=[\"x\", \"y\"])\n",
    "    df[\"label\"] = label.numpy().astype(str)\n",
    "    df = df.sort_values(\"label\")\n",
    "\n",
    "    fig = px.scatter(\n",
    "        df,\n",
    "        x=\"x\",\n",
    "        y=\"y\",\n",
    "        title=\"t-SNE Visualization of Image Data\",\n",
    "        color=\"label\",\n",
    "    )\n",
    "    fig.update_layout(legend_title=\"label\")\n",
    "    return fig\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_tsne(data_reshaped, label)\n",
    "fig.write_image(\"output/metric_learning/tsne_org.png\")\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(101):\n",
    "    if i % 10 != 0:\n",
    "        continue\n",
    "    loaded_data = torch.load(f\"output/metric_learning/pretrained/epoch_{i}_output.pt\")\n",
    "    output_data = loaded_data[\"output\"]\n",
    "    true_label = loaded_data[\"label\"]\n",
    "\n",
    "    fig = plot_tsne(output_data, true_label)\n",
    "    fig.write_image(f\"output/metric_learning/tsne_epoch_{i}.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.line(\n",
    "    pd.read_csv(\"output/metric_learning/pretrained/training_curve.csv\"),\n",
    "    y=[\"train_loss\", \"val_loss\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.line(\n",
    "    pd.read_csv(\"output/metric_learning/pretrained/training_curve.csv\"),\n",
    "    y=[\"val_acc\"],\n",
    ")\n",
    "fig.update_layout(title=\"KNNによるAccuracy\")\n",
    "fig.update_yaxes(title=\"validation Accuracy\")\n",
    "fig.update_xaxes(title=\"epoch\")\n",
    "fig.write_image(\"output/metric_learning/pretrained/accuracy.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
